{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Import </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from math import pow,sqrt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> <b> Train Data </b> is used to search for best parameter / configuration. </p>\n",
    "<p> <b> Test Data </b> is actual testing. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train Data - Load </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = read_csv(\"CencusIncome.csv\", header = None)\n",
    "trainLabel = trainData.loc[:,6]\n",
    "trainLabel, trainLabelLevel = trainLabel.factorize()\n",
    "trainData = trainData.drop(6, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train Data - Preprocessing </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(instance1,instance2):\n",
    "    columnCount = len(instance1)\n",
    "    sum = 0\n",
    "    for i in range(columnCount):\n",
    "        sum += pow(instance1[i]-instance2[i],2)\n",
    "    return sqrt(sum)\n",
    "\n",
    "def normalize(v):\n",
    "    norm = np.linalg.norm(v)\n",
    "    if norm == 0: \n",
    "       return v\n",
    "    return v / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizedTrain = normalize(trainData) \n",
    "print(normalizedTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(normalizedTrain.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Clustering </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_k_medoids(instance, medoids):\n",
    "    row_count = len(medoids.index)\n",
    "    distances = np.zeros(row_count)\n",
    "    for index, row in medoids.iterrows():\n",
    "        distances[index] = euclidean_distance(instance,row)\n",
    "    result = [0, 0]\n",
    "    result[0] = np.argmin(distances)\n",
    "    result[1] = distances[np.argmin(distances)]\n",
    "    return result\n",
    "\n",
    "def k_medoids(df, k, max_iterations):\n",
    "    row_count = len(df.index)\n",
    "    col_count = len(df.columns)\n",
    "    medoids = df.sample(k)\n",
    "    medoids = medoids.reset_index(drop=True)\n",
    "    is_convergence = False;\n",
    "    i = 0\n",
    "    error = 0.0\n",
    "    iteration = 0\n",
    "    #Initiate array for membership\n",
    "    membership = []\n",
    "    for index in range(0,k):\n",
    "        membership.append([])\n",
    "    #First time classify\n",
    "    print(i)\n",
    "    print(datetime.datetime.now())\n",
    "    prev_medoids = medoids.copy()\n",
    "    pred = np.zeros(row_count).astype(int)\n",
    "    #Classify each row & count error\n",
    "    for index, row in df.iterrows():\n",
    "        tmp_array = classify_k_medoids(row, prev_medoids)\n",
    "        pred[index] = tmp_array[0]\n",
    "        membership[tmp_array[0]].append(index)\n",
    "        error += tmp_array[1]\n",
    "    best_error = error\n",
    "    best_pred = np.copy(pred)\n",
    "    best_medoids = medoids.copy()\n",
    "    print(best_error)\n",
    "    print(prev_medoids)\n",
    "    i += 1\n",
    "    \n",
    "    while (not is_convergence):\n",
    "        #Get new medoids (randomize)\n",
    "        random_class = random.randint(0, k-1)\n",
    "        sum_members_of_class = len(membership[random_class])\n",
    "        random_medoid = random.randint(0, sum_members_of_class-1)\n",
    "        #print(\"membership \" + str(membership[random_class]))\n",
    "        print(\"sum member of class\" + str(sum_members_of_class))\n",
    "        print(\"random medoid\" + str(random_medoid))\n",
    "        for index in range(0, col_count):\n",
    "            medoids.iat[random_class, index] = df.iat[random_medoid, index]\n",
    "        print(prev_medoids)\n",
    "        print(medoids)\n",
    "        #Initiate array for membership\n",
    "        membership = []\n",
    "        for index in range(0,k):\n",
    "            membership.append([])\n",
    "        #Classify each row & count error\n",
    "        print(i)\n",
    "        print(datetime.datetime.now())\n",
    "        prev_medoids = medoids.copy()\n",
    "        pred = np.zeros(row_count).astype(int)\n",
    "        error = 0.0        \n",
    "        for index, row in df.iterrows():\n",
    "            tmp_array = classify_k_medoids(row, prev_medoids)\n",
    "            pred[index] = tmp_array[0]\n",
    "            membership[tmp_array[0]].append(index)\n",
    "            error += tmp_array[1]\n",
    "        print(error)\n",
    "\n",
    "        #Stop condition    \n",
    "        #print(membership)\n",
    "        if(error >= best_error):\n",
    "            iteration += 1\n",
    "        else:\n",
    "            iteration = 0\n",
    "            best_error = error\n",
    "            best_pred = np.copy(pred)\n",
    "            best_medoids = medoids.copy()\n",
    "        i += 1\n",
    "        if(iteration == max_iterations):\n",
    "            is_convergence = True\n",
    "    print(\"best error = \" + str(best_error))\n",
    "    print(\"best pred = \" + str(best_pred))\n",
    "    print(\"best medoids = \" + str(best_medoids))\n",
    "    return {\"prediction\": best_pred, \"medoids\": best_medoids} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainResult = k_medoids(normalizedTrain, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train Data - Prepare Prediction Result </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedTrainLabel, predictedTrainLabelLevel = DataFrame(trainResult[\"prediction\"])[0].factorize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train Data - Print Prediction Result </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(trainLabel,predictedTrainLabel))\n",
    "print(metrics.accuracy_score(trainLabel, predictedTrainLabel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Test Data - Load </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = read_csv(\"CencusIncome.csv\", header=None)\n",
    "testLabel = testData.loc[:,6]\n",
    "testLabel, testLabelLevel = testLabel.factorize()\n",
    "testData = testData.drop(6, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Test Data - Preprocess </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizedTest = normalize(testData) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Test Data - Running </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testResult = k_medoids(normalizedTest, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Test Data - Prepare Prediction Result </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionTestLabel, predictionTestLabelLevel = DataFrame(testResult[\"prediction\"])[0].factorize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Test Data - Print Prediction Result </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(testLabel,predictionTestLabel))\n",
    "print(metrics.accuracy_score(testLabel, predictionTestLabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
